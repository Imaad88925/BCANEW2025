import cv2
import mediapipe as mp
import pyautogui
import collections
import time

# Initialize MediaPipe FaceMesh
face_mesh_landmarks = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)
# Open the default camera
cam = cv2.VideoCapture(0)
if not cam.isOpened():
    raise IOError("Cannot open webcam")

# Get screen dimensions
screen_w, screen_h = pyautogui.size()

# Store the last N cursor positions
cursor_history = collections.deque(maxlen=5)

def smooth_cursor(new_x, new_y):
    cursor_history.append((new_x, new_y))
    avg_x = sum(x for x, y in cursor_history) / len(cursor_history)
    avg_y = sum(y for x, y in cursor_history) / len(cursor_history)
    return avg_x, avg_y

# Blink detection variables
blink_start_time = None
blink_count = 0

def detect_blink(left_ear, right_ear, threshold=0.2):
    global blink_start_time, blink_count

    if left_ear < threshold and right_ear < threshold:  # Both eyes closed
        if blink_start_time is None:
            blink_start_time = time.time()
        return True
    else:
        if blink_start_time is not None:
            blink_duration = time.time() - blink_start_time
            blink_start_time = None
            if blink_duration < 0.3:  # Short blink
                blink_count += 1
                if blink_count == 1:
                    pyautogui.click()  # Left-click
                elif blink_count == 2:
                    pyautogui.rightClick()  # Right-click
                    blink_count = 0
            elif blink_duration > 0.5:
                blink_count = 0  # Reset if it's a long blink
        return False

# Dwell click variables
dwell_start = None
dwell_threshold = 1.5  # Time to trigger click (seconds)
last_x, last_y = None, None

def dwell_click(current_x, current_y, threshold=1.5):
    global dwell_start, last_x, last_y

    if last_x is None or last_y is None:
        last_x, last_y = current_x, current_y

    if abs(current_x - last_x) < 20 and abs(current_y - last_y) < 20:  # Eye position stable
        if dwell_start is None:
            dwell_start = time.time()
        elif time.time() - dwell_start > threshold:
            pyautogui.click()
            dwell_start = None
    else:
        dwell_start = None  # Reset if eyes move
    last_x, last_y = current_x, current_y

while True:
    ret, image = cam.read()
    if not ret:
        break

    # Flip the image horizontally
    image = cv2.flip(image, 1)
    window_h, window_w, window_d = image.shape

    # Convert the image to RGB
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Process the image to detect face landmarks
    processed_image = face_mesh_landmarks.process(rgb_image)
    all_face_landmark_points = processed_image.multi_face_landmarks

    if all_face_landmark_points:
        one_face_landmark_points = all_face_landmark_points[0].landmark
        for id, landmark_point in enumerate(one_face_landmark_points[474:478]):
            x = int(landmark_point.x * window_w)
            y = int(landmark_point.y * window_h)
            if id == 1:
                mouse_x = (screen_w / window_w) * x
                mouse_y = (screen_h / window_h) * y
                mouse_x, mouse_y = smooth_cursor(mouse_x, mouse_y)
                pyautogui.moveTo(mouse_x, mouse_y, duration=0.1)  # Add slight delay for smoother movement
                dwell_click(mouse_x, mouse_y, dwell_threshold)  # Check for dwell click
            cv2.circle(image, (x, y), 3, (0, 0, 255))

        left_eye = [one_face_landmark_points[145], one_face_landmark_points[159]]
        right_eye = [one_face_landmark_points[374], one_face_landmark_points[386]]

        # Calculate eye aspect ratios (EAR)
        left_ear = (abs(left_eye[0].y - left_eye[1].y))
        right_ear = (abs(right_eye[0].y - right_eye[1].y))

        # Detect blinks
        if detect_blink(left_ear, right_ear):
            print("Blink detected")

        for landmark_point in left_eye + right_eye:
            x = int(landmark_point.x * window_w)
            y = int(landmark_point.y * window_h)
            cv2.circle(image, (x, y), 3, (0, 255, 255))

    # Display the image
    cv2.imshow("Eye Controlled mouse", image)

    # Exit on 'Esc' key press
    key = cv2.waitKey(10)
    if key == 27:
        break

# Release the camera and close windows
cam.release()
cv2.destroyAllWindows()
